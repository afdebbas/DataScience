{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Classification_Pipelines.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/afdebbas/DataScience/blob/master/Classification_Pipelines.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "DWEj8qgjNTtH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# https://gitlab.com/ppleskov/kaggle-days-dubai"
      ]
    },
    {
      "metadata": {
        "id": "s_6arx7WNTtI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Ultimate Binary Classification Pipeline"
      ]
    },
    {
      "metadata": {
        "id": "tbG-0pq4NTtJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## by Pavel Pleskov - Data Scientist at Point API (https://pointapi.com/)\n"
      ]
    },
    {
      "metadata": {
        "id": "SJPve9BuNTtJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "https://hackernoon.com/interview-with-kaggle-grandmaster-data-scientist-at-point-api-pavel-pleskov-cc8ca67de249"
      ]
    },
    {
      "metadata": {
        "id": "LHYvGWc4NTtK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Example"
      ]
    },
    {
      "metadata": {
        "id": "CrGAY6a9NTtK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "- Humpback Whale Identification https://www.kaggle.com/c/humpback-whale-identification/discussion/82430#latest-482102\n",
        "- Gendered Pronoun Resolution https://www.kaggle.com/c/gendered-pronoun-resolution/discussion/90417#latest-522210"
      ]
    },
    {
      "metadata": {
        "id": "y8V9DrnhNTtL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Motivation"
      ]
    },
    {
      "metadata": {
        "id": "7OPszO_fNTtL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "- a lot of algorithms in sklearn and in other libraries, how to choose?\n",
        "- trade-off between computation time and quality/diversity\n",
        "- proper parameter tuning\n",
        "- blending/stacking"
      ]
    },
    {
      "metadata": {
        "id": "A4KkBcOANTtM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## What will not be covered"
      ]
    },
    {
      "metadata": {
        "id": "u3mXzIFfNTtN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "- Naive Bayes, FFM\n",
        "- imbalanced classes\n",
        "- feature engineering\n",
        "- setting up GPU for boosters"
      ]
    },
    {
      "metadata": {
        "id": "fiirG4G0NTtN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import lightgbm as lgb\n",
        "import xgboost as xgb\n",
        "import catboost as cb\n",
        "from catboost import CatBoostClassifier, Pool\n",
        "import random \n",
        "\n",
        "from os import listdir\n",
        "from tqdm import tqdm\n",
        "from os.path import isfile\n",
        "\n",
        "import sklearn\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler \n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn import preprocessing\n",
        "from sklearn.externals import joblib\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "\n",
        "from bayes_opt import BayesianOptimization\n",
        "from bayes_opt.observer import JSONLogger\n",
        "from bayes_opt.event import Events\n",
        "from bayes_opt.util import load_logs\n",
        "\n",
        "print(\"pandas:\", pd.__version__)\n",
        "print(\"numpy:\", np.__version__)\n",
        "print(\"sklearn:\", sklearn.__version__)\n",
        "print()\n",
        "print(\"lightgbm:\", lgb.__version__)\n",
        "print(\"xgboost:\", xgb.__version__)\n",
        "print(\"catboost:\", cb.__version__)\n",
        "\n",
        "# pip install bayesian-optimization \n",
        "# pip install catboost"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s2gmDOz0NTtQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Downloading the data"
      ]
    },
    {
      "metadata": {
        "id": "abbkbRdTNTtQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Homesite Quote Conversion"
      ]
    },
    {
      "metadata": {
        "id": "4UInY5PuNTtR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "https://www.kaggle.com/c/homesite-quote-conversion/data"
      ]
    },
    {
      "metadata": {
        "id": "Op_qbNTpNTtR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Please follow the link and accept the rules!"
      ]
    },
    {
      "metadata": {
        "id": "6TL5vTZENTtS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!unzip input/homesite-quote-conversion.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "76RfVv31NTtU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "metadata": {
        "id": "u5FzKHVtNTtU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train = pd.read_csv('train.csv')\n",
        "test = pd.read_csv('test.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "b566Ej6xNTtW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train.tail()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nlb2E-q-NTtY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 1. How to use 10% subsample of train set?"
      ]
    },
    {
      "metadata": {
        "id": "x4uMhVJUNTta",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# PUT YOUR CODE HERE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xx4EKlGCNTtc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Dataset seems to be balanced enough"
      ]
    },
    {
      "metadata": {
        "id": "DdcBUjl6NTtd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train.QuoteConversion_Flag.value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5JSyPeuxNTtf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Dealing with dates and categorical variables"
      ]
    },
    {
      "metadata": {
        "id": "HSgaL2WeNTtg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# https://www.kaggle.com/tunguz/xgboost-benchmark-1\n",
        "\n",
        "y = train.QuoteConversion_Flag.values\n",
        "train = train.drop(['QuoteNumber', 'QuoteConversion_Flag'], axis=1)\n",
        "test = test.drop('QuoteNumber', axis=1)\n",
        "\n",
        "# Lets play with some dates\n",
        "train['Date'] = pd.to_datetime(pd.Series(train['Original_Quote_Date']))\n",
        "train = train.drop('Original_Quote_Date', axis=1)\n",
        "\n",
        "test['Date'] = pd.to_datetime(pd.Series(test['Original_Quote_Date']))\n",
        "test = test.drop('Original_Quote_Date', axis=1)\n",
        "\n",
        "train['Year'] = train['Date'].apply(lambda x: int(str(x)[:4]))\n",
        "train['Month'] = train['Date'].apply(lambda x: int(str(x)[5:7]))\n",
        "train['weekday'] = train['Date'].dt.dayofweek\n",
        "\n",
        "test['Year'] = test['Date'].apply(lambda x: int(str(x)[:4]))\n",
        "test['Month'] = test['Date'].apply(lambda x: int(str(x)[5:7]))\n",
        "test['weekday'] = test['Date'].dt.dayofweek\n",
        "\n",
        "train = train.drop('Date', axis=1)\n",
        "test = test.drop('Date', axis=1)\n",
        "\n",
        "train = train.fillna(-1)\n",
        "test = test.fillna(-1)\n",
        "\n",
        "for f in tqdm(train.columns):\n",
        "    if train[f].dtype=='object':\n",
        "        #print(f)\n",
        "        lbl = preprocessing.LabelEncoder()\n",
        "        lbl.fit(list(train[f].values) + list(test[f].values))\n",
        "        train[f] = lbl.transform(list(train[f].values))\n",
        "        test[f] = lbl.transform(list(test[f].values))\n",
        "        \n",
        "# train-test discrepancy analysis is skipped"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cWlhK08RNTth",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train.tail()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lgEQrJ6mNTtj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cols = list(train.columns)\n",
        "len(cols), cols"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_9zCGjGuNTtl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Reducing dimensionality"
      ]
    },
    {
      "metadata": {
        "id": "jUEfUjinNTtm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# PUT YOUR CODE HERE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "T8jjEzKqNTto",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Using column subsample in order to speed calulation up"
      ]
    },
    {
      "metadata": {
        "id": "HkQ9_DA9NTto",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Naive approach\n",
        "# random.seed(42)\n",
        "# cols = random.sample(cols, 50) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MN2VaHefNTtq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 2. Why explained variance is always close to 100%?"
      ]
    },
    {
      "metadata": {
        "id": "MnXAKaoXNTtq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "N = 50\n",
        "\n",
        "svd = TruncatedSVD(n_components=N, random_state=42)\n",
        "X = svd.fit_transform(train[cols], y)  \n",
        "svd.explained_variance_ratio_.sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sIJg0I4jNTts",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame()\n",
        "df[\"target\"] = y\n",
        "\n",
        "for i in range(50):\n",
        "    df[i] = X[:,i]\n",
        "    \n",
        "df.to_csv(\"partial_train_\"+str(N)+\".csv\", index=False)\n",
        "\n",
        "df.tail()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jmNZCyWSNTtv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## LogReg"
      ]
    },
    {
      "metadata": {
        "id": "uQPVtcIqNTtv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 3. What is wrong with this code?"
      ]
    },
    {
      "metadata": {
        "id": "snB1IOseNTtw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "arch = \"reg\"\n",
        "\n",
        "train[arch] = 0\n",
        "\n",
        "for i, (train_index, valid_index) in enumerate(skf.split(X, y)):\n",
        "    \n",
        "    X_train = X[train_index]\n",
        "    X_valid = X[valid_index]\n",
        "\n",
        "    y_train = y[train_index]\n",
        "    y_valid = y[valid_index]\n",
        "    \n",
        "    reg = LogisticRegression().fit(X_train, y_train) \n",
        "    \n",
        "    y_pred = reg.predict_proba(X_valid)[:,1]\n",
        "    train.loc[valid_index, arch] = y_pred\n",
        "    print(i, \"ROC AUC:\", round(roc_auc_score(y_valid, y_pred), 5))\n",
        "\n",
        "print()\n",
        "print(\"OOF ROC AUC:\", round(roc_auc_score(y, train[arch]), 5))\n",
        "print()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VSPbhjz0NTtz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## SVM"
      ]
    },
    {
      "metadata": {
        "id": "ycFXAMS-NTtz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 4. What is wrong with this algorithm? (at least two things)"
      ]
    },
    {
      "metadata": {
        "id": "_k4xCc89NTt0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# https://github.com/Xtra-Computing/thundergbm\n",
        "# pip install thundersvm-cpu-0.2.0-py3-none-linux_x86_64.whl\n",
        "# from thundersvm import SVC"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vgOSSg-RNTt2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "arch = \"svc\"\n",
        "\n",
        "train[arch] = 0\n",
        "\n",
        "for i, (train_index, valid_index) in enumerate(skf.split(X, y)):\n",
        "    \n",
        "    X_train = X[train_index]\n",
        "    X_valid = X[valid_index]\n",
        "\n",
        "    y_train = y[train_index]\n",
        "    y_valid = y[valid_index]\n",
        "    \n",
        "    svc = SVC().fit(X_train, y_train) \n",
        "    \n",
        "    y_pred = svc.predict_proba(X_valid)[:,1]\n",
        "    train.loc[valid_index, arch] = y_pred\n",
        "    print(i, \"ROC AUC:\", round(roc_auc_score(y_valid, y_pred), 5))\n",
        "\n",
        "print()\n",
        "print(\"OOF ROC AUC:\", round(roc_auc_score(y, train[arch]), 5))\n",
        "print()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nZA7W5GPNTt5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## KNN"
      ]
    },
    {
      "metadata": {
        "id": "jI2kSLH0NTt6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 5. How can we produce more models with KNN? "
      ]
    },
    {
      "metadata": {
        "id": "jthn5_n4NTt6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "arch = \"nei\"\n",
        "\n",
        "train[arch] = 0\n",
        "\n",
        "for i, (train_index, valid_index) in enumerate(skf.split(X, y)):\n",
        "    \n",
        "    X_train = X[train_index]\n",
        "    X_valid = X[valid_index]\n",
        "\n",
        "    y_train = y[train_index]\n",
        "    y_valid = y[valid_index]\n",
        "    \n",
        "    nei = KNeighborsClassifier(p=1, n_jobs=-1).fit(X_train, y_train) \n",
        "    \n",
        "    y_pred = nei.predict_proba(X_valid)[:,1]\n",
        "    train.loc[valid_index, arch] = y_pred\n",
        "    print(i, \"ROC AUC:\", round(roc_auc_score(y_valid, y_pred), 5))\n",
        "    \n",
        "print()\n",
        "print(\"OOF ROC AUC:\", round(roc_auc_score(y, train[arch]), 5))\n",
        "print()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Rom9YrlRNTt8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Random Forest"
      ]
    },
    {
      "metadata": {
        "id": "34JOxxb2NTt8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 6. Which optimization metric is used by RFC?"
      ]
    },
    {
      "metadata": {
        "id": "MhGLM6VFNTt9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "arch = \"rfc\"\n",
        "\n",
        "train[arch] = 0\n",
        "test[arch] = 0\n",
        "\n",
        "for i, (train_index, valid_index) in enumerate(skf.split(X, y)):\n",
        "    \n",
        "    X_train = X[train_index]\n",
        "    X_valid = X[valid_index]\n",
        "\n",
        "    y_train = y[train_index]\n",
        "    y_valid = y[valid_index]\n",
        "    \n",
        "    rfc = RandomForestClassifier(n_estimators=100,\n",
        "                                 n_jobs=-1).fit(X_train, y_train) \n",
        "    \n",
        "    y_pred = rfc.predict_proba(X_valid)[:,1]\n",
        "    train.loc[valid_index, arch] = y_pred\n",
        "    print(i, \"ROC AUC:\", round(roc_auc_score(y_valid, y_pred), 5))\n",
        "\n",
        "print()\n",
        "print(\"OOF ROC AUC:\", round(roc_auc_score(y, train[arch]), 5))\n",
        "print()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "G5rsXs5UNTt-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## LGBM"
      ]
    },
    {
      "metadata": {
        "id": "-Wa_u52bNTt-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 7. How to save LGBM model? What is it anyway?"
      ]
    },
    {
      "metadata": {
        "id": "c_K8v70RNTt_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "arch = \"lgb\"\n",
        "\n",
        "train[arch] = 0\n",
        "\n",
        "rounds = 10000\n",
        "early_stop_rounds = 300\n",
        "\n",
        "params = {'objective': 'binary',\n",
        "          'boosting_type': 'gbrt',\n",
        "          'metric': 'auc',\n",
        "          'seed': 42,\n",
        "          'max_depth': -1,\n",
        "          'verbose': -1,\n",
        "          'n_jobs': -1}\n",
        "\n",
        "# best_params = {'feature_fraction': 0.8752556106728574,\n",
        "#               'lambda_l1': 1.3735569040447826,\n",
        "#               'lambda_l2': 8.04774809406042,\n",
        "#               'learning_rate': 0.024553401275571943,\n",
        "#               'min_data_in_leaf': 16.31456193667883,\n",
        "#               'min_sum_hessian_in_leaf': 10.489617646270466,\n",
        "#               'num_leaves': 14.623398745206696}\n",
        "\n",
        "# best_params['num_leaves'] = int(best_params['num_leaves'])\n",
        "# best_params['min_data_in_leaf'] = int(best_params['min_data_in_leaf'])\n",
        "# params.update(best_params)\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "for i, (train_index, valid_index) in enumerate(skf.split(X, y)):\n",
        "    \n",
        "    X_train = X[train_index]\n",
        "    X_valid = X[valid_index]\n",
        "\n",
        "    y_train = y[train_index]\n",
        "    y_valid = y[valid_index]\n",
        "\n",
        "    d_train = lgb.Dataset(X_train, y_train)\n",
        "    d_valid = lgb.Dataset(X_valid, y_valid)    \n",
        "\n",
        "    model = lgb.train(params,\n",
        "                      d_train,\n",
        "                      num_boost_round=rounds,\n",
        "                      valid_sets=[d_train, d_valid],\n",
        "                      valid_names=['train','valid'],\n",
        "                      early_stopping_rounds=early_stop_rounds,\n",
        "                      verbose_eval=0) \n",
        "    \n",
        "    # PUT YOUR CODE HERE\n",
        "\n",
        "    y_pred = model.predict(X_valid)\n",
        "    train.loc[valid_index, arch] = y_pred\n",
        "    auc = roc_auc_score(y_valid, y_pred)\n",
        "    print(i, \"ROC AUC:\", round(auc, 5))\n",
        "\n",
        "print()\n",
        "print(\"OOF ROC AUC:\", round(roc_auc_score(y, train[arch]), 5))\n",
        "print()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "31i9REmMNTuB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Feature importance"
      ]
    },
    {
      "metadata": {
        "id": "lRpx7IjTNTuB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 8. How to load the model?"
      ]
    },
    {
      "metadata": {
        "id": "yr5iWl0tNTuC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# PUT YOUR CODE HERE\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(15, 10))\n",
        "lgb.plot_importance(model, max_num_features=50, ax=ax)\n",
        "plt.title(\"Light GBM Feature Importance\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QU8FTGWkNTuE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## HPO"
      ]
    },
    {
      "metadata": {
        "id": "UJEEhJxWNTuE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def evaluate(**new_params):\n",
        "\n",
        "    rounds = 10000\n",
        "    early_stop_rounds = 300\n",
        "    \n",
        "    new_params['num_leaves'] = int(new_params['num_leaves'])\n",
        "    new_params['min_data_in_leaf'] = int(new_params['min_data_in_leaf'])\n",
        "    \n",
        "    params.update(new_params)\n",
        "    print(new_params)\n",
        "    \n",
        "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "    oof = np.zeros(len(train))\n",
        "    \n",
        "    for i, (train_index, valid_index) in enumerate(skf.split(X, y)):\n",
        "    \n",
        "        X_train = X[train_index]\n",
        "        X_valid = X[valid_index]\n",
        "\n",
        "        y_train = y[train_index]\n",
        "        y_valid = y[valid_index]\n",
        "\n",
        "        d_train = lgb.Dataset(X_train, y_train)\n",
        "        d_valid = lgb.Dataset(X_valid, y_valid)    \n",
        "\n",
        "        model = lgb.train(params,\n",
        "                          d_train,\n",
        "                          num_boost_round=rounds,\n",
        "                          valid_sets=[d_train, d_valid],\n",
        "                          valid_names=['train','valid'],\n",
        "                          early_stopping_rounds=early_stop_rounds,\n",
        "                          verbose_eval=0) \n",
        "        \n",
        "        oof[valid_index] = model.predict(X_valid)\n",
        "        auc = roc_auc_score(y[valid_index], oof[valid_index])\n",
        "        print(i, \"ROC AUC:\", round(auc, 5))\n",
        "    \n",
        "    auc = roc_auc_score(y, oof)\n",
        "    print()\n",
        "    print(\"ROC AUC VALID:\", round(auc, 5))\n",
        "    print()\n",
        "        \n",
        "    return auc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "12syayi2NTuI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 9. Which parameters to optimize?"
      ]
    },
    {
      "metadata": {
        "id": "f0VrUL52NTuI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# https://github.com/fmfn/BayesianOptimization\n",
        "\n",
        "params = {'objective': 'binary',\n",
        "          'boosting_type': 'gbrt',\n",
        "          'metric': 'auc',\n",
        "          'bagging_freq': 1,\n",
        "          'bagging_fraction': 0.9,\n",
        "          'bagging_seed': 42,\n",
        "          'seed': 42,\n",
        "          'max_bin': 1023, #255\n",
        "          'max_depth': -1,\n",
        "          'verbose': -1,\n",
        "          'n_jobs': -1}\n",
        "\n",
        "bounds = {'num_leaves': (4,32), \n",
        "          'learning_rate': (0.01,0.05)\n",
        "          # PUT YOUR CODE HERE\n",
        "         }\n",
        "\n",
        "bo = BayesianOptimization(evaluate, pbounds=bounds)\n",
        "\n",
        "log_file = \"./output/hpo_lgbm_logs.json\"\n",
        "logger = JSONLogger(path=log_file)\n",
        "bo.subscribe(Events.OPTMIZATION_STEP, logger)\n",
        "\n",
        "bo.maximize(init_points=2, n_iter=8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "p0wNkR7WNTuJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "bo.max"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tkWkx4jWNTuM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## XGB"
      ]
    },
    {
      "metadata": {
        "id": "tukRURPBNTuM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 10. Pros and cons of using XGB?"
      ]
    },
    {
      "metadata": {
        "id": "TBGXZ50CNTuN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "arch = \"xgb\"\n",
        "\n",
        "train[arch] = 0\n",
        "\n",
        "rounds = 10000\n",
        "early_stop_rounds = 100\n",
        "\n",
        "params = {'eval_metric': 'auc',\n",
        "          'booster': 'gbtree',\n",
        "          'tree_method': 'hist',\n",
        "          'objective': 'binary:logistic',\n",
        "          'subsample': 0.9,\n",
        "          'colsample_bytree': 0.3,\n",
        "          'eta': 0.1,\n",
        "          'max_depth': 4,\n",
        "          'seed': 42,\n",
        "          'verbosity': 0}\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "for i, (train_index, valid_index) in enumerate(skf.split(X, y)):\n",
        "    \n",
        "    X_train = X[train_index]\n",
        "    X_valid = X[valid_index]\n",
        "\n",
        "    y_train = y[train_index]\n",
        "    y_valid = y[valid_index]\n",
        "\n",
        "    d_train = xgb.DMatrix(X_train, y_train)\n",
        "    d_valid = xgb.DMatrix(X_valid, y_valid)\n",
        "\n",
        "    model = xgb.train(params,\n",
        "                      d_train,\n",
        "                      rounds,\n",
        "                      [(d_train, 'train'), (d_valid, 'eval')],\n",
        "                      early_stopping_rounds=early_stop_rounds,\n",
        "                      verbose_eval=0)\n",
        "    \n",
        "    #joblib.dump(model, f\"./output/xgb_{i}.pkl\")\n",
        "\n",
        "    best = model.best_iteration + 1\n",
        "\n",
        "    y_pred = model.predict(d_valid, ntree_limit=best)\n",
        "    train.loc[valid_index, arch] = y_pred\n",
        "    auc = roc_auc_score(y_valid, y_pred)\n",
        "    print(i, \"ROC AUC:\", round(auc, 5))\n",
        "\n",
        "print()\n",
        "print(\"OOF ROC AUC:\", round(roc_auc_score(y, train[arch]), 5))\n",
        "print()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hOHhk0hVNTuO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## CatBoost"
      ]
    },
    {
      "metadata": {
        "id": "5eX8EqNqNTuP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 11. Pros and cons of using CatBoost?"
      ]
    },
    {
      "metadata": {
        "id": "LbXy5r7ANTuQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "arch = \"cat\"\n",
        "\n",
        "train[arch] = 0\n",
        "\n",
        "rounds = 10000\n",
        "early_stop_rounds = 100\n",
        "\n",
        "params = {'task_type': 'CPU', #GPU\n",
        "          'iterations': rounds,\n",
        "          'loss_function': 'Logloss',\n",
        "          'eval_metric':'AUC',\n",
        "          'random_seed': 42,\n",
        "          'learning_rate': 0.5,\n",
        "          'depth': 2}\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "for i, (train_index, valid_index) in enumerate(skf.split(X, y)):\n",
        "    \n",
        "    X_train = X[train_index]\n",
        "    X_valid = X[valid_index]\n",
        "\n",
        "    y_train = y[train_index]\n",
        "    y_valid = y[valid_index]\n",
        "    \n",
        "    trn_data = Pool(X_train, y_train)\n",
        "    val_data = Pool(X_valid, y_valid)\n",
        "    \n",
        "    clf = CatBoostClassifier(**params)\n",
        "    clf.fit(trn_data,\n",
        "            eval_set=val_data,\n",
        "            use_best_model=True,\n",
        "            early_stopping_rounds=early_stop_rounds,\n",
        "            verbose=0)\n",
        "    \n",
        "    y_pred = clf.predict_proba(X_valid)[:, 1]\n",
        "    train.loc[valid_index, arch] = y_pred\n",
        "    auc = roc_auc_score(y_valid, y_pred)\n",
        "    print(i, \"ROC AUC:\", round(auc, 5))\n",
        "\n",
        "print()\n",
        "print(\"OOF ROC AUC:\", round(roc_auc_score(y, train[arch]), 5))\n",
        "print()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5YASp4XBNTuR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## NN"
      ]
    },
    {
      "metadata": {
        "id": "6QNnHq0xNTuR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 12. What is wrong with this code? (answer also applies to all boosters)"
      ]
    },
    {
      "metadata": {
        "id": "ruuyjvRbNTuS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import fastai\n",
        "import torch\n",
        "\n",
        "from fastai.basic_data import load_data\n",
        "from fastai.tabular import *\n",
        "\n",
        "print(\"fastai:\", fastai.__version__)\n",
        "print(\"torch:\", torch.__version__)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iSIE8w7TNTuT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "path = Path('../output/')\n",
        "bs = 2048\n",
        "\n",
        "procs = [FillMissing, Categorify, Normalize]\n",
        "\n",
        "dep_var = \"target\"\n",
        "\n",
        "cat_names = []\n",
        "cont_names = []\n",
        "\n",
        "df = pd.read_csv(\"partial_train_\"+str(N)+\".csv\")\n",
        "cont_names = list(df.columns)\n",
        "cont_names.remove('target')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SDAXQDQqNTuV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def auc_score(y_pred,y_true,tens=True):\n",
        "    score = roc_auc_score(y_true, torch.sigmoid(y_pred)[:, 1])\n",
        "    if tens:\n",
        "        score = tensor(score)\n",
        "    else:\n",
        "        score = score\n",
        "    return score\n",
        "\n",
        "random_seed = 42\n",
        "\n",
        "np.random.seed(random_seed)\n",
        "random.seed(random_seed)\n",
        "torch.manual_seed(random_seed)\n",
        "torch.cuda.manual_seed(random_seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "I5YTcxg8NTuW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "arch = \"nn\"\n",
        "\n",
        "train[arch] = 0\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "for i, (train_index, valid_index) in enumerate(skf.split(X, y)):\n",
        "    \n",
        "    data = (TabularList.from_df(df, path=path, cat_names=cat_names,\n",
        "                                cont_names=cont_names, procs=procs)\n",
        "                       .split_by_idx(valid_index)\n",
        "                       .label_from_df(cols=dep_var)\n",
        "                       .databunch(bs=bs))\n",
        "    \n",
        "    learn = tabular_learner(data, \n",
        "                            layers=[20, 10],\n",
        "                            ps=0.5,\n",
        "                            emb_drop=0.5,\n",
        "                            y_range=[0, 1],\n",
        "                            use_bn=True,\n",
        "                            metrics=[auc_score])\n",
        "    lr = 1e-2\n",
        "    \n",
        "    learn.fit_one_cycle(10, lr, moms=(0.8, 0.7))\n",
        "    learn.fit_one_cycle(10, lr/2, moms=(0.8, 0.7))\n",
        "        \n",
        "    preds = learn.get_preds(ds_type=DatasetType.Valid)\n",
        "    y_pred = [float(preds[0][i][1]) for i in range(len(preds[0]))]\n",
        "    \n",
        "    train.loc[valid_index, arch] = y_pred\n",
        "    auc = roc_auc_score(y[valid_index], y_pred)\n",
        "    print(i, \"ROC AUC:\", round(auc, 5))\n",
        "\n",
        "print()\n",
        "print(\"OOF ROC AUC:\", round(roc_auc_score(y, train[arch]), 5))\n",
        "print()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0T1gVrveNTuX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Correlation"
      ]
    },
    {
      "metadata": {
        "id": "4tnRbGTxNTuY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 13. How to fix this code?"
      ]
    },
    {
      "metadata": {
        "id": "G_K_uXmBNTua",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "models = [\"reg\", \"nei\", \"rfc\", \"lgb\", \"xgb\", \"cat\", \"nn\"]\n",
        "\n",
        "# PUT YOUR CODE HERE\n",
        "\n",
        "train[models].corr()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9i9ePcRNNTud",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train[models].tail()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WzcnTVKPNTuf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Blending"
      ]
    },
    {
      "metadata": {
        "id": "i6xJUhvENTuf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for arch in models:\n",
        "    print(arch, round(roc_auc_score(y, train[arch]), 5))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HPKIAqHiNTui",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let's try traditional arithmetic mean"
      ]
    },
    {
      "metadata": {
        "id": "tXajmgJlNTuj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train[\"avg\"] = train[models].mean(axis=1)\n",
        "print(\"avg\", round(roc_auc_score(y, train[\"avg\"]), 5))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TCQj5ri9NTuk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now some more advanced means"
      ]
    },
    {
      "metadata": {
        "id": "HJMwJozvNTuk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from scipy.stats.mstats import gmean\n",
        "\n",
        "def power_mean(x, p=1):\n",
        "    if p==0:\n",
        "        return gmean(x, axis=1)\n",
        "    return np.power(np.mean(np.power(x,p), axis=1), 1/p)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IY2RiJpMNTun",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 14. Which powers to check?"
      ]
    },
    {
      "metadata": {
        "id": "cKgOiqJgNTun",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# PUT YOUR CODE HERE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OE31WsJtNTuq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 15. How to choose weights?"
      ]
    },
    {
      "metadata": {
        "id": "GjDIMB5RNTuq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "w = [1,1,1,1,1,1,1,1] # CHANGE YOUR CODE HERE\n",
        "\n",
        "train[\"w_avg\"] = 0\n",
        "for i, model in enumerate(models):\n",
        "    train[\"w_avg\"] += train[model] * w[i]\n",
        "\n",
        "print(\"w_avg\", round(roc_auc_score(y, train[\"w_avg\"]), 5))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wwhEYd2tNTus",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Stacking"
      ]
    },
    {
      "metadata": {
        "id": "O3PTH1eINTus",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 16. How hard could it be?"
      ]
    },
    {
      "metadata": {
        "id": "Io_JZKrGNTut",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# PUT YOUR CODE HERE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0kGd3fEYNTuu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 17. How to get weights?"
      ]
    },
    {
      "metadata": {
        "id": "gGzP5UJ0NTuu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# PUT YOUR CODE HERE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2XSOFrmFNTuv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## H2O"
      ]
    },
    {
      "metadata": {
        "id": "Y8NiOXu3NTuw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 18. What is the point anyway? "
      ]
    },
    {
      "metadata": {
        "id": "Gqm0nlYFNTuw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# pip install h2o\n",
        "# https://github.com/h2oai/h2o-tutorials/blob/master/h2o-world-2017/automl/Python/automl_binary_classification_product_backorders.ipynb\n",
        "\n",
        "import h2o\n",
        "from h2o.automl import H2OAutoML\n",
        "h2o.init()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KV3Qx709NTux",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data_path = \"partial_train_\"+str(N)+\".csv\"\n",
        "df = h2o.import_file(data_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "umr-egbINTuy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lPDmUqmFNTu1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "target = \"C1\"\n",
        "x = df.columns\n",
        "x.remove(target)\n",
        "\n",
        "df[target] = df[target].asfactor() # important line"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "f1tNRLPPNTu3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "aml = H2OAutoML(max_models = 10, seed = 1)\n",
        "aml.train(x = x, y = target, training_frame = df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "scxdkSyeNTu4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "lb = aml.leaderboard\n",
        "lb.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6YzxvbPENTu5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Get model ids for all models in the AutoML Leaderboard\n",
        "model_ids = list(aml.leaderboard['model_id'].as_data_frame().iloc[:,0])\n",
        "# Get the \"All Models\" Stacked Ensemble model\n",
        "se = h2o.get_model([mid for mid in model_ids if \"StackedEnsemble_AllModels\" in mid][0])\n",
        "# Get the Stacked Ensemble metalearner model\n",
        "metalearner = h2o.get_model(se.metalearner()['name'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uSznXQheNTu7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "metalearner.coef_norm()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "v19RA0OBNTu9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "metalearner.std_coef_plot()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}